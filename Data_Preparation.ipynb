{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import gc\n",
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "mnse.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patients from infancy to adolescence that are admitted to a Pediatric Intensive Care Unit and monitored\n",
    "by EEG are the primary focus of this research. Only patients in a comatose state are included in this\n",
    "focus. Patients may be medically induced for a number of unspecified reasons, such as traumatic brain\n",
    "injury, cardiac arrest, but also to treat prolonged or severe seizures. There are a total of 127 EEG\n",
    "recordings from unique subjects available, each with a distinct duration that sums up to nearly 138\n",
    "days of continuous data. The average recording duration per subject is 26 hours.\n",
    "\n",
    "A case selection is applied, where only EEG recordings containing one or more seizures are eligible for\n",
    "further research. This might provide the DL model more targeted information about the distinctive\n",
    "patterns associated with epileptic seizures, rather than also including data from patients that did not\n",
    "contain any seizures during the recording. The limitation of this is that the model is not inclusive\n",
    "of patients that have no seizures. It might not be able to accurately detect and classify segments of\n",
    "recordings that are completely free of seizures. The selection reduces the available data to 37 EEG\n",
    "recordings that include seizures, which now consists of a total of nearly 78 days of continuous data\n",
    "available, of which 3 days account for seizures. Only EEG data is selected for to limit memory constraints\n",
    "while loading data. This is considered a necessary preprocessing step.\n",
    "\n",
    "Despite this modification, there\n",
    "are still 6 out of the 37 selected files that cannot be fully loaded due to its considerable size. Since they\n",
    "contain many seizures, the six recordings are handled differently to still include them in the selection. The six long recordings that cannot be fully loaded are handled in segments. These large files are\n",
    "cropped by its seizure annotations, resulting in a Raw object for each individual seizure. These are\n",
    "loaded and concatenated at a later point. The same amount on non-seizure data from this subject\n",
    "is then loaded in segments as well. This selection is in line with the data mining goals, regardless of\n",
    "the technical limitations. The downside of this approach is that, due to fixed length epoching done at\n",
    "a later point, this means that short seizures with a duration of less than 10 seconds are completely\n",
    "excluded. This ends up leaving out a total of 12 seizures with a duration between 1.5 and 8.9 seconds\n",
    "across the six files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_channels = [\n",
    "    'Fp1', 'Fp2', 'F3',\n",
    "    'F4', 'F7', 'F8',\n",
    "    'Fz', 'C3', 'C4',\n",
    "    'Cz', 'T3', 'T4', \n",
    "    'T5', 'T6', 'P3',\n",
    "    'P4', 'Pz', 'O1', 'O2'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the data is loaded and cleaned, it is first read with necessary preprocessing steps, such as\n",
    "inferring channel types and only selecting EEG channels. While all the files are read individually, files\n",
    "that contain no annotations with the description indicative of a seizure, they are skipped. After this,\n",
    "each file can be loaded and undergo steps that are considered cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of raw EEG recording\n",
    "def preprocess(raw):\n",
    "    try:\n",
    "        # Channel types are not always inferred correly\n",
    "        raw.set_channel_types({ch: 'eeg' for ch in raw.ch_names})\n",
    "        # Channel positions and digitization points\n",
    "        raw.set_montage('standard_1020')\n",
    "        # Removes electrical noise creating 50 Hz artefacts\n",
    "        raw.notch_filter(np.arange(50,101,50))\n",
    "        # Bandpass filter (Delta - Gamma band)\n",
    "        raw.filter(0.1, 70)\n",
    "        # Average of all channels is used as reference\n",
    "        raw.set_eeg_reference(ref_channels='average')\n",
    "\n",
    "        print('Cleaned and filtered')\n",
    "\n",
    "        sfreq = raw.info['sfreq']\n",
    "        if sfreq != 256.0:\n",
    "            print(f'Sampling frequency is {int(sfreq)} Hz')\n",
    "            raw.resample(sfreq=256.0)\n",
    "            print(f'Resampled to 256 Hz')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seizure labels are stored in Rawâ€™s annotations. They can be found using its description. The\n",
    "annotations are converted to a DataFrame, which results in the onset and duration and in seconds for\n",
    "each seizure per recording. By summing these, the end time of the seizure is calculated and added to\n",
    "the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract seizure annotations and create DataFrame with start and end times\n",
    "def seizure_annotations(raw):\n",
    "    sz_annotations = raw.annotations[raw.annotations.description == 'AANVAL']\n",
    "    print(f'Found {len(sz_annotations)} seizures')\n",
    "\n",
    "    raw.set_annotations(sz_annotations)\n",
    "    \n",
    "    df_sz_annotations = pd.DataFrame(sz_annotations, columns=['onset', 'duration'])\n",
    "    df_sz_annotations['end'] = df_sz_annotations['onset'] + df_sz_annotations['duration']\n",
    "    \n",
    "    return df_sz_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data mining goal is to classify EEG segments, fixed length epochs are created from the recording.\n",
    "After consulting, it was decided that each epoch will be 10 seconds long with no overlap. The epochs\n",
    "are converted to a DataFrame, and the original time in seconds is restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed length segments (epochs) from EEG recording\n",
    "def create_epochs(raw, duration, overlap):\n",
    "    try:\n",
    "        # Fixed length segments (epochs) from EEG\n",
    "        epochs = mne.make_fixed_length_epochs(raw, duration, overlap)\n",
    "        print('Epoched')\n",
    "        del raw\n",
    "        gc.collect()\n",
    "\n",
    "        df_epochs = epochs.to_data_frame()\n",
    "        del epochs\n",
    "        gc.collect()\n",
    "        print('Converted to DataFrame')\n",
    "        \n",
    "        df_epochs.drop(columns=['condition'], inplace=True)\n",
    "        # Add original time from EEG recording\n",
    "        df_epochs['count'] = df_epochs.index / 256\n",
    "\n",
    "        if 'Pz' not in df.epochs.columns:\n",
    "            print(f'Pz is missing')\n",
    "            eeg_cols = [col for col in df_epochs.columns if col != 'count']\n",
    "            df_epochs['Pz'] = df_epochs[eeg_cols].mean(axis=1)\n",
    "            print(f'Filled with mean values')\n",
    "        \n",
    "        # Round EEG values to 2 decimal places to save memory\n",
    "        for col in eeg_channels:\n",
    "            df_epochs[col] = df_epochs[col].round(2)\n",
    "        print('Values rounded')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    return df_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The epochs DataFrame and seizure annotations are merged on the count of the recording and the\n",
    "onset of each seizure. A column is added to add binary labels to, indicating each row as seizure (1) or\n",
    "non-seizure (0). Each row at closest time match between each seizure start and end time are marked\n",
    "as 1. With the memory constraints it is not yet possible to merge the data of all the recordings into\n",
    "one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary labels to indicate seiure/non-seizure datapoints\n",
    "def labeling(df_epochs, df_sz_annotations):\n",
    "    # Add seizures times to DataFrame by merging\n",
    "    df = pd.merge_asof(df_epochs, df_sz_annotations, left_on='count', right_on='onset')\n",
    "    del df_epochs\n",
    "    gc.collect()\n",
    "\n",
    "    # Initialize default value to indicate sample as non-seizure (0)\n",
    "    df['seizure'] = 0\n",
    "\n",
    "    # Sample indication changes to seizure (1) at closest match\n",
    "    df.loc[(df['count'] >= df['onset']) & (df['count'] <= df['end']), 'seizure'] = 1\n",
    "    print(f\"Labeled\")\n",
    "    \n",
    "    # Seizure times can now be removed\n",
    "    df.drop(columns=[\"count\", \"onset\", \"end\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, all values are presented as floats with 6 decimal places. This precision is not needed\n",
    "and rounding all values to 2 decimal places will save memory and be more computationally efficient. This is done during epoching.\n",
    "\n",
    "The data mining goals state that segments should be classified as seizure or non-seizure. The epochs\n",
    "are created, but the DataFrame still presents each data point as an individual row. Reshaping takes\n",
    "place so that each record represents an entire epoch of 10 seconds. This is done by grouping and\n",
    "aggregating float values and putting them an array. The target column can now present an entire\n",
    "epoch as seizure/non-seizure. Its value is set to the (first) most common value.\n",
    "This means that, e.g., an epoch with 6 seconds of seizure data will be considered a seizure segment.\n",
    "On the other hand, an epoch with 4 seconds of seizure data will be considered a non-seizure segment.\n",
    "This approach is approved from the expert perspective. Appointing seizure labels to epochs that\n",
    "consist of only seizure data is also possible. There is no right of wrong approach, but it should be a\n",
    "conscious design choice. This decision is made to not further reduce the occurrence of seizure epochs.\n",
    "Another approach is to make sure that you are not falling into a seizure or non-seizure area\n",
    "within the same epoch.\n",
    "\n",
    "It should be mentioned that, besides the excluded seizures from the problem handling section, more seizures\n",
    "are excluded because of this. Luckily, seizures shorter than 5 seconds do not occur often in the data. One of the recordings (M15_0000615#01) only contains one seizure that lasts 3\n",
    "seconds. The seizure is too short to be classified as a seizure epoch, and this leaves no other seizures in\n",
    "this recording. Because of this, the subject is no longer included in the data selection. This reduces\n",
    "the number of subjects selected for further analysis to 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape DataFrame for each record to represent each epoch\n",
    "def reshape_df(df):\n",
    "    agg = {}\n",
    "\n",
    "    for channel in eeg_channels:\n",
    "        agg[channel] = df.groupby('epoch')[channel].apply(lambda x: np.array(x.tolist(), dtype=np.float32))\n",
    "    \n",
    "    seizure_label = df.groupby('epoch')['seizure'].apply(lambda x: x.mode().iat[0])\n",
    "\n",
    "    df = pd.DataFrame(agg)\n",
    "    df['seizure'] = seizure_label.values\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    print('Reshaped')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every recording contains more non-seizure epochs than seizure epochs. To avoid class imbalance, the\n",
    "DataFrame is separated based on the target value. The number of seizure epochs per recording is\n",
    "calculated, after which the same number of non-seizure epochs are selected randomly. These two\n",
    "subsets are concatenated, presenting the final DataFrame per recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate epochs based on target value (seizure)\n",
    "def epochs_seizure_based(df):\n",
    "    df_sz_epochs = df.loc[df['seizure'] == 1].reset_index(drop=True)\n",
    "    \n",
    "    # Count number of seizure epochs for this patient\n",
    "    N = df_sz_epochs.shape[0]\n",
    "    print(f'Recording has {N} seizure epochs')\n",
    "\n",
    "    # Randomly select N non-seizure epochs\n",
    "    df_no_sz_epochs = df.loc[df['seizure'] == 0].sample(n=N, random_state=42).reset_index(drop=True)\n",
    "    print(f' {N} random non-seizure epochs selected')\n",
    "    \n",
    "    df = pd.concat([df_sz_epochs, df_no_sz_epochs], axis=0).reset_index(drop=True)\n",
    "    print('Balanced DataFrame')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting the subject ID for later identification, each DataFrame is exported to a feather file.\n",
    "This format is chosen for its high read and write performance, and ability to store complex data types\n",
    "efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pseudonym from filename\n",
    "def extract_subject_id(output_filename):\n",
    "    parts = os.path.splitext(output_filename)[0].split('_')\n",
    "    if 'epoched' in parts[-2]:\n",
    "        return '_'.join(parts[2:-2])\n",
    "    else:\n",
    "        return '_'.join(parts[2:-1])\n",
    "    \n",
    "# Export DataFrame to FEATHER file\n",
    "def df_conversion(df, output_folder, output_filename):\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "    subject_id = extract_subject_id(output_filename)\n",
    "    df.insert(0, 'subject', subject_id)\n",
    "\n",
    "    df.to_feather(output_path)\n",
    "\n",
    "    print('Exported data to FEATHER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths with relevant system prefix\n",
    "def define_paths(project_dir, data_dir):\n",
    "    SYSTEM = platform.system()\n",
    "    if SYSTEM not in ('Windows', 'Linux'):\n",
    "        raise Exception(f'Unsupported plaform: {SYSTEM}')\n",
    "    disk_prefix = None\n",
    "    if SYSTEM == 'Windows':\n",
    "        disk_prefix = 'Z:/'\n",
    "    elif SYSTEM == 'Linux':\n",
    "        disk_prefix == '/media/mount/'\n",
    "    \n",
    "    project_path = os.path.join(disk_prefix, project_dir)\n",
    "    data_path = os.path.join(project_path, data_dir)\n",
    "\n",
    "    return project_path, data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all EDF files in data directory\n",
    "def select_edf_files(data_path):\n",
    "    edf_files = [file for file in os.listdir(data_path) if file.endswith('.edf')]\n",
    "    print(f{len(edf_files)} EDF files available)\n",
    "\n",
    "    return edf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading file and optional loading\n",
    "def load_raw(file, seizure_files_only, loading):\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(file, infer_types=True, include=eeg_channels)\n",
    "        print('Read')\n",
    "\n",
    "        if seizure_files_only:\n",
    "            if not any('AANVAL' in ann['description'] for ann in raw.annotations):\n",
    "                del raw\n",
    "                gc.collect()\n",
    "                raise Exception(f'Recording has no seizures... exiting')\n",
    "        \n",
    "        if loading:\n",
    "            raw = raw.load_data()\n",
    "            print('Loaded')\n",
    "        \n",
    "        return raw\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'{file} is not loaded: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and select files\n",
    "project_path, data_path = define_paths(project_dir, data_dir='_01_Raw_Data/EDF/')\n",
    "output_path = define_paths(project_dir, data_dir= '_04_Epoched_Data/FEATHER/')\n",
    "\n",
    "edf_files = select_edf_files(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run loading and preprocessing functions\n",
    "def loading(data_path, file, loading):\n",
    "    '''\n",
    "    Reads and optionally loads EEG recordings with MNE\n",
    "\n",
    "    Args:\n",
    "        data_path: data location (str)\n",
    "        file: selected EEG filename (str)\n",
    "    \n",
    "    Returns:\n",
    "        raw: read/loaded EEG files (mne.io.Raw)\n",
    "    \n",
    "    Raises:\n",
    "        MemoryError: some files are too large and raise\n",
    "            an error when exceeding available memory\n",
    "    '''\n",
    "\n",
    "    file = os.path.join(data_path, file)\n",
    "    raw = load_raw(file, seizure_files_only=True, loading=loading)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(raw):\n",
    "    '''\n",
    "    Prepares the data for the use of modeling\n",
    "    Includes filtering, setting annotations, epoching data, \n",
    "    and creating DataFrame with labeled encoding\n",
    "\n",
    "    Args:\n",
    "        raw: EEG recording (mne.io.Raw)\n",
    "    \n",
    "    Raises:\n",
    "        MemoryError: some files are too large and raise\n",
    "            an error when exceeding available memory\n",
    "    '''\n",
    "    \n",
    "    raw = preprocess(raw)\n",
    "    annotations = seizure_annotations(raw)\n",
    "    epochs = create_epochs(raw, duration=10.0, overlap=0.0)\n",
    "\n",
    "    df = labeling(epochs, annotations)\n",
    "    df = reshape_df(df)\n",
    "    df = epochs_seizure_based(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "    print(f'...Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions defined above are executed in a loop for each file individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(edf_files, start=1):\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'Handling {file}... EEG {index}/{len(edf_files)}')\n",
    "    try:\n",
    "        raw = loading(data_path, file, loading=True)\n",
    "        df = preprocessing(raw)\n",
    "        output_filename = os.path.splitext(file)[0] + '_epoched.feather'\n",
    "        df_conversion(df, output_path, output_filename)\n",
    "    except Exception as e:\n",
    "        print(f'Error with {file}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing epoch files\n",
    "folder_raw = data_path\n",
    "\n",
    "seizure_files = [\n",
    " 'EXP_EMC_BR2_0000210#01.edf','EXP_EMC_BR3_0000495#01.edf','EXP_EMC_BR3_0000520#01.edf',\n",
    " 'EXP_EMC_M15_0000099#01.edf','EXP_EMC_M15_0000106#01.edf','EXP_EMC_M15_0000120#01.edf',\n",
    " 'EXP_EMC_M15_0000139#01.edf','EXP_EMC_M15_0000151#01.edf','EXP_EMC_M15_0000241#01.edf',\n",
    " 'EXP_EMC_M15_0000311#01.edf','EXP_EMC_M15_0000333#01.edf','EXP_EMC_M15_0000434#01.edf',\n",
    " 'EXP_EMC_M15_0000469#01.edf','EXP_EMC_M15_0000556#01.edf','EXP_EMC_M15_0000568#01.edf',\n",
    " 'EXP_EMC_M15_0000574#01.edf','EXP_EMC_M15_0000615#01.edf','EXP_EMC_M16_0000070#01.edf',\n",
    " 'EXP_EMC_M16_0000109#01.edf','EXP_EMC_M16_0000110#01.edf','EXP_EMC_M16_0000111#01.edf',\n",
    " 'EXP_EMC_M16_0000153#01.edf','EXP_EMC_M16_0000168#01.edf','EXP_EMC_M16_0000232#01.edf',\n",
    " 'EXP_EMC_M16_0000233#01.edf','EXP_EMC_M16_0000243#01.edf','EXP_EMC_M16_0000244#01.edf',\n",
    " 'EXP_EMC_M16_0000351#01.edf','EXP_EMC_M16_0000541#01.edf','EXP_EMC_M16_0000542#01.edf',\n",
    " 'EXP_EMC_M16_0000555#01.edf','EXP_EMC_M16_0000579#01.edf','EXP_EMC_M16_0000580#01.edf',\n",
    " 'EXP_EMC_M16_0000583#01.edf','EXP_EMC_M16_0000600#01.edf','EXP_EMC_M18_0001180#01.edf',\n",
    " 'EXP_EMC_M6b_0000513#01.edf'\n",
    " ]\n",
    "\n",
    "files_epoched = [file for file in os.listdir(output_folder) if file.endswith('_epoched.feather')]\n",
    "\n",
    "missing_files = [file for file in seizure_files if file[:-4] + '_epoched.feather' not in files_epoched]\n",
    "print(f'Missing epoched seizure files: {len(missing_files)}')\n",
    "for file in missing_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(missing_files, start=1):\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'Handling {file}... EEG {index}/{len(edf_files)}')\n",
    "    try:\n",
    "        raw = loading(data_path, file, loadig=False)\n",
    "        seizures = df_sz_annotations\n",
    "        N = seizure.shape[0]\n",
    "\n",
    "        intervals_df = pd.DataFrame(columns = ['start', 'end'])\n",
    "        for x in range(len(seizures)):\n",
    "            if x == 0:\n",
    "                intervals_df.loc[x,'start'] = 0\n",
    "                intervals_df.loc[x, 'end'] = seizures.loc[x, 'onset']\n",
    "            else:\n",
    "                intervals_df.loc[x,'start'] = seizures.loc[x-1, 'end']\n",
    "                intervals_df.loc[x, 'end'] = seizures.loc[x, 'onset']\n",
    "        \n",
    "        last_start = seizures.iloc[-1, 1]\n",
    "        last_end = (raw.last_samp / raw.info['sfreq']) - 1\n",
    "        intervals_df.loc[len(intervals_df.index)] = [last_start, last_end]\n",
    "        intervals_df['label'] = 'interictal'\n",
    "\n",
    "        onsets = intervals_df['start'].values\n",
    "        durations = intervals_df['end'].values - intervals_df['start'].values\n",
    "        descriptions = intervals_df['label'].values\n",
    "\n",
    "        annotations = mne.Annotations(onsets, durations, descriptions)\n",
    "        raw.set_annotations(annotations)\n",
    "        annotations = raw.annotations[raw.annotations.description == 'interictal']\n",
    "        n_annotations = int(len(annotations) * 0.3)\n",
    "        annotations = random.sample(list(annotations), n_annotations)\n",
    "        print(len(annotations), 'annotations selected')\n",
    "\n",
    "        raws = raw.crop_by_annotations(annotations)\n",
    "        print('Cropped by annotations')\n",
    "\n",
    "        epochs = []\n",
    "        for raw in tqdm(raws):\n",
    "            try:\n",
    "                raw.load_data()\n",
    "                preprocess(raw)\n",
    "\n",
    "                segment = mne.make_fixed_length_epochs(raw, 10.0, 0.0)\n",
    "                epochs.append(segment)\n",
    "                print('Loaded, preprocessed, and epoched')\n",
    "                del raw\n",
    "                gc.collect()\n",
    "\n",
    "            except Exception:\n",
    "                print(f'Segment {raw} is too short to epoch')\n",
    "        \n",
    "        del raws\n",
    "        gc.collect()\n",
    "\n",
    "        epochs = mne.concatenate_epochs(epochs)\n",
    "        print('Concatenated epochs')\n",
    "        df = epochs.to_data_frame()\n",
    "        print('Created DataFrame')\n",
    "        df.drop(columns=['condition', inplace=True])\n",
    "        df['seizure'] = 0\n",
    "\n",
    "        del epochs\n",
    "        gc.collect()\n",
    "\n",
    "        df = reshape_df(df)\n",
    "        df = df.sample(n=N, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        output_filename = os.path.splitext(file)[0] + '_epoched.feather'\n",
    "        df_conversion(df, output_path, output_filename)\n",
    "\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error with {file}: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
